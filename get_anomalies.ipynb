{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Anomaly Detection Baseline\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydub\n",
    "import numpy as np\n",
    "from sound.sound_eval import eval_sound\n",
    "from matplotlib import pyplot as plt\n",
    "from time_series.anomaly_detection import polyreg_outliar_mse, lof\n",
    "from time_series.smoothening_functions import  kaiser_wind\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Helper Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_linreg(arr, n, linreg):\n",
    "    \"\"\"\n",
    "    Evaluate linear regression predictions\n",
    "\n",
    "    Args:\n",
    "        arr: Data to operate on. This include both the data that will be processed by the regressor and the ground\n",
    "        truth that should be predicted\n",
    "        n: Size of autoregressor window such that every n samples form the data from which sample n+1 will be predicted.\n",
    "        linreg: Trained linear regressor\n",
    "\n",
    "    Returns:\n",
    "        Squares of the differences between predictions and ground truth\n",
    "    \"\"\"\n",
    "    arr     = np.array(arr).reshape((len(arr),))\n",
    "    windows = []\n",
    "    labels  = []\n",
    "    for i in range(len(arr) - n):\n",
    "        windows.append(arr[i : i + n])\n",
    "        labels.append(arr[i + n])\n",
    "    return (linreg.predict(windows) - labels)**2\n",
    "\n",
    "\n",
    "def get_anomls(arr, signal, thr):\n",
    "    segms   = []\n",
    "    i       = 0\n",
    "    while i < len(arr):\n",
    "        if arr[i] == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        start = i\n",
    "        while i < len(arr) and arr[i]>thr:\n",
    "            i += 1\n",
    "        if len(signal[i - 180 : i + 180]) > 0:\n",
    "            segms.append([start, np.max(np.array(signal[i - 180 : i + 180])), i])\n",
    "        i += 1\n",
    "    return segms\n",
    "\n",
    "\n",
    "def get_ap(tot_length, res, labels, start = 0, ends = None):\n",
    "    if not ends:\n",
    "        ends = len(res)\n",
    "    ground_truth = np.zeros((tot_length*6,))\n",
    "    for l in labels:\n",
    "        strt, end   = l[0], l[1]\n",
    "        strt        = (strt % 100) + 60 * int(strt / 100)\n",
    "        end         = (end % 100) + 60 * int(end / 100)\n",
    "        for i in range(max(0, strt*6-90),min(len(ground_truth),end*6+90)):\n",
    "            ground_truth[i] = 1\n",
    "    return  average_precision_score(ground_truth[start:ends], res),\\\n",
    "            precision_score(ground_truth[start:ends], res > 0.5),\\\n",
    "            recall_score(ground_truth[start:ends], res > 0.5)\n",
    "\n",
    "def get_ap_at_k(tot_length, segms, labels):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    segms           = reversed(segms)\n",
    "    ground_truth    = np.zeros((tot_length*6,))\n",
    "    starts          = np.zeros((tot_length*6,))\n",
    "    ends            = np.zeros((tot_length*6,))\n",
    "    for l in labels:\n",
    "        strt, end   = l[0], l[1]\n",
    "        strt        = (strt % 100) + 60 * int(strt / 100)\n",
    "        end         = (end % 100) + 60 * int(end / 100)\n",
    "        for i in range(max(0, strt * 6 - 90), min(len(ground_truth), end * 6 +90)):\n",
    "            ground_truth[i] = 1\n",
    "        starts[strt*6 - 10 : strt*6 + 10]   = 1\n",
    "        ends[end*6 - 10 : end*6 + 10]       = 1\n",
    "    count_starts    = 0\n",
    "    sums_starts     = 0\n",
    "    count_end       = 0\n",
    "    sums_end        = 0\n",
    "    count_coverage  = 0\n",
    "    sums_coverage   = 0\n",
    "    for i, s in enumerate(segms):\n",
    "        if i > 6:\n",
    "            break\n",
    "        # Get starts\n",
    "        if np.sum(starts[s[0]-90:s[0]+60])>0:\n",
    "            print(\"start \", i + 1)\n",
    "            count_starts    += 1\n",
    "            sums_starts     += count_starts/(i+1)\n",
    "        \n",
    "        # Get ends\n",
    "        if np.sum(ends[s[-1]-60:min(s[-1]+90, len(ends))])>0:\n",
    "            print(\"end \", i + 1)\n",
    "            count_end   += 1\n",
    "            sums_end    += count_end/(i+1)\n",
    "        \n",
    "        # Get coverage\n",
    "        if np.mean(ground_truth[s[0]:s[-1]]) > 0.5:\n",
    "            print(\"coverage \", i + 1)\n",
    "            count_coverage  += 1\n",
    "            sums_coverage   += count_coverage/(i+1)\n",
    "    \n",
    "    return sums_starts/max(1,count_starts), sums_end/max(1,count_end), sums_coverage/max(1,count_coverage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the names of the required data files without the extensions (those files should be in the ./data/ folder)\n",
    "audio_file          = \"test\"    # Audio file for analysis. Must be a single-channel/mono MP3 file\n",
    "frame_analysis_file = \"test\"    # File containing autoencoder reconstruction loss values. Should be a .csv file\n",
    "labels_file         = \"test\"    # File containg the labels (highlights) should be a .txt file in the format (per line):\n",
    "                                # 'mm:ss - mm:ss' representing (start_time - end_time)\n",
    "\n",
    "# Set the parameters for the length of the video\n",
    "minutes = 60\n",
    "seconds = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length    = 60 * minutes + seconds\n",
    "labels          = []\n",
    "\n",
    "# Parse the .txt file containing the labels\n",
    "with open(os.path.join('data', labels_file + \".txt\"), \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        start_time, end_time                    = line.split(\"-\")\n",
    "        start_time_minutes, start_time_seconds  = start_time.split(\":\")\n",
    "        end_time_minutes, end_time_seconds      = end_time.split(\":\")\n",
    "        labels.append([int(start_time_minutes.strip() + start_time_seconds.strip()),\n",
    "                       int(end_time_minutes.strip() + end_time_seconds.strip())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyse the given audio file\n",
    "a                       = pydub.AudioSegment.from_mp3(f\"data/{audio_file}.mp3\")\n",
    "y                       = np.array(a.get_array_of_samples())\n",
    "data_binr, data_rmsr, _ = eval_sound(y,a)\n",
    "plt.plot(data_binr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoencoder reconstruction loss values\n",
    "singl_frm = np.loadtxt(f\"data/{frame_analysis_file}.csv\", delimiter = \",\")\n",
    "plt.plot(singl_frm)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "#### Perform LOF on Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interm = np.array(data_binr)\n",
    "r = 480\n",
    "interm  = lof(interm, r )\n",
    "signal  = interm\n",
    "\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "print(np.quantile(interm, 0.999))\n",
    "interm = interm >= np.quantile(interm, 0.999) + 0\n",
    "interm  = kaiser_wind(interm, 180, 0.2 )\n",
    "interm[interm>1] = 1\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "\n",
    "segms = get_anomls(interm, signal, 0.5)\n",
    "print(len(interm))\n",
    "print(len(segms))\n",
    "for s in segms:\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "segms.sort(key=lambda x: x[1])\n",
    "print(\"============\")\n",
    "\n",
    "for s in segms:\n",
    "    print(s[0] / 360, s[-1] / 360, s[1])\n",
    "ap, prec, rec = get_ap(video_length, interm, labels)\n",
    "print(\"AP:\", ap)\n",
    "print(\"PRECISION:\", prec)\n",
    "print(\"RECALL:\", rec)\n",
    "print(\"START@6, END@6, COVERAGE@6\", get_ap_at_k(video_length, segms, labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get LOF of Single Frame Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(singl_frm))\n",
    "interm = np.array(singl_frm)\n",
    "r = 240\n",
    "interm  = lof(interm, r )\n",
    "signal  = interm\n",
    "\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "print( np.quantile(interm, 0.995))\n",
    "interm = interm > np.quantile(interm, 0.995) + 0\n",
    "interm  = kaiser_wind(interm, 360, 0.1 )\n",
    "interm[interm>1] = 1\n",
    "\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "segms = get_anomls(interm, signal, 0.5)\n",
    "print(len(interm))\n",
    "print(len(segms))\n",
    "for s in segms:\n",
    "    s[0]-=90\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "segms.sort(key=lambda x: x[1])\n",
    "\n",
    "\n",
    "print(\"============\")\n",
    "for s in segms:\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "ap, prec, rec = get_ap(video_length, interm, labels, start = 90, ends = len(interm)+90)\n",
    "print(\"AP:\", ap)\n",
    "print(\"PRECISION:\", prec)\n",
    "print(\"RECALL:\", rec)\n",
    "print(\"START@6, END@6, COVERAGE@6\",get_ap_at_k(video_length, segms, labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressor on Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "r = 180\n",
    "d_interm = sc.fit_transform(X  =np.array(data_binr).reshape(-1,1), y = None)\n",
    "plt.plot(d_interm)\n",
    "plt.show()\n",
    "unsup_linreg = polyreg_outliar_mse([d_interm.reshape(-1,)],r)\n",
    "interm = eval_linreg(kaiser_wind(d_interm.reshape(-1,), r+30, 2), r, unsup_linreg)\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "print( np.quantile(interm, 0.95))\n",
    "interm = interm > np.quantile(interm, 0.95) + 0\n",
    "interm  = kaiser_wind(interm, 360, 0.1 )\n",
    "interm[interm>1] = 1\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "segms = get_anomls(interm, signal, 0.5)\n",
    "print(len(segms))\n",
    "for s in segms:\n",
    "    s[0]+=2*r\n",
    "    s[-1]+=2*r\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "segms.sort(key=lambda x: x[1])\n",
    "print(\"============\")\n",
    "\n",
    "\n",
    "for s in segms:\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "ap, prec, rec = get_ap(video_length, interm, labels, start = 2*r, ends = len(interm)+2*r )\n",
    "print(\"AP:\", ap)\n",
    "print(\"PRECISION:\", prec)\n",
    "print(\"RECALL:\", rec)\n",
    "print(\"START@6, END@6, COVERAGE@6\",get_ap_at_k(video_length, segms, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73b38e9ef86264810bcf595cb60c9ac1d316c70176c08b8f95e9d155205a5f37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
