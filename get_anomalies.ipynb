{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sound.sound_eval import eval_sound\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pydub\n",
    "from time_series.anomaly_detection import polyreg_outliar_mse, lof\n",
    "from time_series.smoothening_functions import power_smooth, llr_smooth, ewma_bias_corrected, kaiser_wind,derivative\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the names of the required data files without the extensions (those files should be in the ./data/ folder)\n",
    "# The audio file should be a .mp3 file and the audio NEEDS TO BE MONO !!!\n",
    "audio_file = \"test\"\n",
    "# The file containing the single frame analysis should be a .csv file\n",
    "frame_analysis_file = \"test\"\n",
    "# The file containg the labels should be a .txt file in the required format\n",
    "# (per line: 'mm:ss - mm:ss' representing (start time) - (end time))\n",
    "labels_file = \"test\"\n",
    "\n",
    "# Set the parameters for the length of the video\n",
    "minutes = 60\n",
    "seconds = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_legnth  = 60 * minutes + seconds\n",
    "labels = []\n",
    "\n",
    "# Parse the .txt file containing the labels\n",
    "with open(os.path.join('data', labels_file + \".txt\"), \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        start_time, end_time = line.split(\"-\")\n",
    "        start_time_minutes, start_time_seconds = start_time.split(\":\")\n",
    "        end_time_minutes, end_time_seconds = end_time.split(\":\")\n",
    "        labels.append([int(start_time_minutes.strip() + start_time_seconds.strip()), int(end_time_minutes.strip() + end_time_seconds.strip())])\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to evaluate the linear regression:\n",
    "def eval_linreg(arr, n, linreg):\n",
    "    arr = np.array(arr).reshape((len(arr),))\n",
    "    windows = []\n",
    "    labels = []\n",
    "    for i in range(len(arr)-n):\n",
    "        windows.append(arr[i:i+n])\n",
    "        labels.append(arr[i+n])\n",
    "    return (linreg.predict(windows) - labels)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mp3 of the audio !!! NEEDS TO BE MONO !!!\n",
    "a = pydub.AudioSegment.from_mp3(\"data/\" + audio_file + \".mp3\")\n",
    "        \n",
    "y = np.array(a.get_array_of_samples())\n",
    "data_binr, data_rmsr, _ = eval_sound(y,a)\n",
    "plt.plot(data_binr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the single frame analysis\n",
    "singl_frm = np.loadtxt(\"data/\" + frame_analysis_file + \".csv\", delimiter = \",\")\n",
    "plt.plot(singl_frm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract anomalous segments\n",
    "def get_anomls(arr, signal, thr):\n",
    "    segms = []\n",
    "    \n",
    "    \n",
    "    print(thr)\n",
    "    i = 0\n",
    "    while i < len(arr):\n",
    "        if arr[i] == 0:\n",
    "            i+=1\n",
    "            continue\n",
    "        start = i\n",
    "        while i < len(arr) and arr[i]>thr:\n",
    "            i+=1\n",
    "        \n",
    "        \n",
    "        \n",
    "        segms.append([start, np.max(np.array(signal[i-180:i+180])), i])\n",
    "        i+=1\n",
    "    return segms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def get_ap(tot_length, res, labels,start = 0, ends = None):\n",
    "    if not ends:\n",
    "        ends = len(res)\n",
    "    ground_truth = np.zeros((tot_length*6,))\n",
    "    for l in labels:\n",
    "        strt, end = l[0], l[1]\n",
    "        strt = (strt%100)+60*int(strt/100)\n",
    "        end = (end%100)+60*int(end/100)\n",
    "        for i in range(max(0, strt*6-90),min(len(ground_truth),end*6+90)):\n",
    "            ground_truth[i] = 1\n",
    "    return average_precision_score(ground_truth[start:ends], res), precision_score(ground_truth[start:ends], res > 0.5), recall_score(ground_truth[start:ends], res, res > 0.5)\n",
    "\n",
    "def get_ap_at_k(tot_length, segms, labels):\n",
    "    segms = reversed(segms)\n",
    "    ground_truth = np.zeros((tot_length*6,))\n",
    "    starts = np.zeros((tot_length*6,))\n",
    "    ends = np.zeros((tot_length*6,))\n",
    "    for l in labels:\n",
    "        strt, end = l[0], l[1]\n",
    "        strt = (strt%100)+60*int(strt/100)\n",
    "        end = (end%100)+60*int(end/100)\n",
    "        for i in range(max(0, strt*6-90),min(len(ground_truth),end*6+90)):\n",
    "            ground_truth[i] = 1\n",
    "        starts[strt*6-10:strt*6+10] = 1\n",
    "        ends[end*6-10: end*6+10] = 1\n",
    "    count_starts = 0\n",
    "    sums_starts = 0\n",
    "    count_end = 0\n",
    "    sums_end = 0\n",
    "    count_coverage = 0\n",
    "    sums_coverage = 0\n",
    "    for i, s in enumerate(segms):\n",
    "        if i > 6:\n",
    "            break\n",
    "        # Get starts:\n",
    "        if np.sum(starts[s[0]-90:s[0]+60])>0:\n",
    "            print(\"start \",i+1)\n",
    "            count_starts += 1\n",
    "            sums_starts += count_starts/(i+1)\n",
    "        \n",
    "        # Get ends:\n",
    "        if np.sum(ends[s[-1]-60:min(s[-1]+90, len(ends))])>0:\n",
    "            print(\"end \",i+1)\n",
    "            count_end += 1\n",
    "            sums_end += count_end/(i+1)\n",
    "        # get coverage\n",
    "        if np.mean(ground_truth[s[0]:s[-1]])>0.5:\n",
    "            print(\"coverage \",i+1)\n",
    "            count_coverage += 1\n",
    "            sums_coverage += count_coverage/(i+1)\n",
    "    \n",
    "    return sums_starts/max(1,count_starts), sums_end/max(1,count_end), sums_coverage/max(1,count_coverage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform LOF on audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_binr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m interm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mdata_binr\u001b[49m)\n\u001b[0;32m      2\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m480\u001b[39m\n\u001b[0;32m      3\u001b[0m interm  \u001b[38;5;241m=\u001b[39m lof(interm, r )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_binr' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "interm = np.array(data_binr)\n",
    "r = 480\n",
    "interm  = lof(interm, r )\n",
    "signal  = interm\n",
    "\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "print(np.quantile(interm, 0.999))\n",
    "interm = interm >= np.quantile(interm, 0.999) + 0\n",
    "interm  = kaiser_wind(interm, 180, 0.2 )\n",
    "interm[interm>1] = 1\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "\n",
    "print(len(interm))\n",
    "segms = get_anomls(interm, signal, 0.5)\n",
    "print(len(segms))\n",
    "# segm_means = [np.mean(np.array(i)) for i in segms]\n",
    "# print(segm_means)\n",
    "for s in segms:\n",
    "    # s[0]-=r/2\n",
    "    # s[-1]+=180\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "segms.sort(key=lambda x: x[1])\n",
    "print(\"============\")\n",
    "\n",
    "for s in segms:\n",
    "    # s[0]-=180\n",
    "    # s[-1]+=180\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "ap, prec, rec = get_ap(video_legnth, interm, labels)\n",
    "print(\"AP:\", ap)\n",
    "print(\"PRECISION:\", prec)\n",
    "print(\"RECALL:\", rec)\n",
    "print(\"START@6, END@6, COVERAGE@6\", get_ap_at_k(video_legnth, segms, labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get LOF of Single frame reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segms = SWIDE_ours(kaiser_wind(lof(np.array(data_binr), 360),180,4), 5)\n",
    "print(len(singl_frm))\n",
    "interm = np.array(singl_frm)\n",
    "r = 240\n",
    "interm  = lof(interm, r )\n",
    "signal  = interm\n",
    "\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "print( np.quantile(interm, 0.995))\n",
    "interm = interm > np.quantile(interm, 0.995) + 0\n",
    "interm  = kaiser_wind(interm, 360, 0.1 )\n",
    "interm[interm>1] = 1\n",
    "\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "segms = get_anomls(interm, signal, 0.5)\n",
    "print(len(interm))\n",
    "print(len(segms))\n",
    "# segm_means = [np.mean(np.array(i)) for i in segms]\n",
    "# print(segm_means)\n",
    "for s in segms:\n",
    "    s[0]-=90\n",
    "    # s[-1]+=90\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "segms.sort(key=lambda x: x[1])\n",
    "\n",
    "\n",
    "print(\"============\")\n",
    "for s in segms:\n",
    "    # s[0]-=180\n",
    "    # s[-1]+=180\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "ap, prec, rec = get_ap(video_legnth, interm, labels, start = 90, ends = len(interm)+90)\n",
    "print(\"AP:\", ap)\n",
    "print(\"PRECISION:\", prec)\n",
    "print(\"RECALL:\", rec)\n",
    "print(\"START@6, END@6, COVERAGE@6\",get_ap_at_k(video_legnth, segms, labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor on audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "r = 180\n",
    "d_interm = sc.fit_transform(X  =np.array(data_binr).reshape(-1,1), y = None)\n",
    "# d_interm = np.log(np.array(data_binr))\n",
    "# d_interm = data_binr\n",
    "plt.plot(d_interm)\n",
    "plt.show()\n",
    "unsup_linreg = polyreg_outliar_mse([d_interm.reshape(-1,)],r)\n",
    "interm = eval_linreg(kaiser_wind(d_interm.reshape(-1,), r+30, 2), r, unsup_linreg)\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "print( np.quantile(interm, 0.95))\n",
    "interm = interm > np.quantile(interm, 0.95) + 0\n",
    "interm  = kaiser_wind(interm, 360, 0.1 )\n",
    "interm[interm>1] = 1\n",
    "plt.plot(interm)\n",
    "plt.show()\n",
    "segms = get_anomls(interm, signal, 0.5)\n",
    "print(len(segms))\n",
    "# segm_means = [np.mean(np.array(i)) for i in segms]\n",
    "# print(segm_means)\n",
    "for s in segms:\n",
    "    # s[0]-=r/2\n",
    "    s[0]+=2*r\n",
    "    s[-1]+=2*r\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "segms.sort(key=lambda x: x[1])\n",
    "print(\"============\")\n",
    "\n",
    "\n",
    "for s in segms:\n",
    "    # s[0]-=180\n",
    "    # s[-1]+=180\n",
    "    print(s[0]/360, s[-1]/360, s[1])\n",
    "ap, prec, rec = get_ap(video_legnth, interm, labels, start = 2*r, ends = len(interm)+2*r )\n",
    "print(\"AP:\", ap)\n",
    "print(\"PRECISION:\", prec)\n",
    "print(\"RECALL:\", rec)\n",
    "print(\"START@6, END@6, COVERAGE@6\",get_ap_at_k(video_legnth, segms, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73b38e9ef86264810bcf595cb60c9ac1d316c70176c08b8f95e9d155205a5f37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
